[{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://tue-mps.github.io/author/mps-lab/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mps-lab/","section":"authors","summary":"","tags":null,"title":"MPS Lab","type":"authors"},{"authors":["吳恩達"],"categories":null,"content":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da99cb196019cc5857b9b3e950397ca9","permalink":"https://tue-mps.github.io/author/%E5%90%B3%E6%81%A9%E9%81%94/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/%E5%90%B3%E6%81%A9%E9%81%94/","section":"authors","summary":"吳恩達 is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"吳恩達","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://tue-mps.github.io/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":null,"categories":["Internship"],"content":"Important note: this project is provisional, and the details may be subject to change.\nSummary: During this project, you will implement, train and evaluate a Reinforcement Learning method for driving in a 3D simulation enviornment\nType: Internship\nStarting date: September 2021\nSupervisor: Arash Roomi Zadeh\nGeneral description:\nSafe navigation in urban environments remains a challenging problem for autonomous vehicles. Reinforcement Learning (RL) algorithms have shown great success in many behavior generation applications when the agent has access to a reliable state signal such as video game playing tasks. This motivates researchers to also use RL for decision-making for automated driving. Despite these achievements, the state-of-the-art RL methods for automated driving still cannot achieve safety requirements for real-world autonomous driving. This is due to both non-practicality of training in the real world, the uncertain nature of the observations, and the stochastic nature of the driving environment.\nTraditionally, RL algorithms choose actions that maximize mean return value. This is desired in domains in which failure has a low impact. However, in real-world driving tasks, events with low probability but a high impact (e.g., rare collision types) also play a critical role in policy generation. This motivates using risk evaluation for policy generation for decision-making. Risk-sensitive optimization of distributional DQN networks has been employed in fields in which risk-avoidance is critical and has got promising results.\nThe first goal of this internship is to implement a Distributional Reinforcement Learning algorithm and use it for driving policy risk evaluation. Secondly, the aim is to provide this algorithm with extra information about uncertainty such as detection accuracy and occlusions, to generate safe driving policies.\nWe use two environments for training and evaluation, a 2D gym environment and a realistic 3D simulation environment (CARLA).\nTask description: During this project, you will carry out the following tasks:\n Implement and evaluate a baseline Distributional Reinforcement Learning (DRL) agent in the CARLA environment. For this task, you will need to integrate a scene understanding method such as semantic segmentation with a DRL agent. Train and evaluate a baseline agent in presence of observation uncertainties. Train and evlauate an agent provided with the observation uncertainty information.  Prerequisites:\n Good programming and neural networks implementation skills. Theoretical knowledge about neural networks. General knowledge about reinforcement learning and/or high motivation to learn.  Interested? Send an email to a.roomi.zadeh@tue.nl, containing:\n Brief motivation letter List of relevant courses and grades  References and further reading\n [1] The CARLA Autonomous Driving Leaderboard [2] M.G. Bellemare, W. Dabney, R. Munos, \u0026ldquo;A Distributional Perspective on Reinforcement Learning\u0026rdquo;, International Conference on Machine Learning 2017. ","date":1629331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629331200,"objectID":"a50c42bd62c89d3b098f3e5f0fc76804","permalink":"https://tue-mps.github.io/post/2021-09-internship-risk-aware-decision-making/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/post/2021-09-internship-risk-aware-decision-making/","section":"post","summary":"Important note: this project is provisional, and the details may be subject to change.\nSummary: During this project, you will implement, train and evaluate a Reinforcement Learning method for driving in a 3D simulation enviornment\n","tags":null,"title":"Teach a driving agent what it cannot see","type":"post"},{"authors":null,"categories":["Internship"],"content":"Important note: this project is provisional, and the details may be subject to change.\nSummary: During this project, you will be able to model the interactions between vehicles to improve trajectory prediction of those vehicles.\nType: Internship\nStarting date: September 2021\nSupervisor: Ariyan Bighashdel\nGeneral description:\nDeveloping Advanced Driving Assistance Systems (ADAS) can play a crucial role in reducing the number of injuries and deaths, related to motor vehicle accidents. Although this is encouraging, ADAS still have significant challenges when it comes to driving in more crowded areas. In these situations, forecasting the future movements of vehicles is a vital task in producing collision-free paths. However, trajectory prediction of the vehicles has remained a complex problem due to numerous factors, one of which is the interactions between the vehicles.\nIn the last decades, the subject of interaction modeling has been extensively addressed in the literature for pedestrian path prediction purposes. For many years, researchers heavily relied on traditional approaches with hand-crafted models to interpret the interactions between humans in crowded areas. After the dawn of deep learning, researchers had the opportunity to rely on more learning-based methods to infer the interactions. The developed learning-based methods have shown promising results for pedestrian path prediction in various scenarios with dominating human-human interactions.\nTo date, few studies have examined the association between human-human and vehicle-vehicle interaction modeling methods. Therefore, the goal of this project is to develop a vehicle trajectory prediction framework with various interaction modeling methods which are inspired from human-human interaction modeling, and compare them in a well-controlled study.\nTask description: During this project, you will accomplish the following goals:\n Implementing a vehicle path prediction model with an encoder-decoder LSTM network. Implementing three human-human interaction modeling methods: 1) discrete social pooling [1] 2) continuous social pooling [2] and 3) graph attention [3], in the vehicle path prediction model. Evaluation and comparison of the three interaction modeling methods on the rounD vehicle trajectory dataset [4].  Prerequisites:\n Experience with the implementation of recurrent neural networks.  Interested? Send an email to a.bighashdel@tue.nl, containing:\n Brief motivation letter List of relevant courses and grades  References\n[1] A. Alahi, K. Goel, V. Ramanathan, A. Robicquet, L. Fei-Fei, and S. Savarese, \u0026ldquo;Social lstm: Human trajectory prediction in crowded spaces,\u0026rdquo; in Computer Pision and Pattern Recognition (CVPR), 2016, pp. 961-971.\n[2] A. Gupta, J. Johnson, L. Fei-Fei, S. Savarese, and A. Alahi, \u0026ldquo;Social gan: Socially acceptable trajectories with generative adversarial networks,\u0026rdquo; in Computer Pision and Pattern Recognition (CVPR), 2018, pp. 2255-2264.\n[3] Y. Huang, H. Bi, Z. Li, T. Mao, and Z. Wang, \u0026ldquo;Stgat: Modeling spatial-temporal interactions for human trajectory prediction,\u0026rdquo; in International Conference on Computer Vision (ICCV), 2019, pp. 6272-6281.\n[4] R. Krajewski, T. Moers, J. Bock, L. Vater, and L. Eckstein, \u0026ldquo;The rounD Dataset: A Drone Dataset of Road User Trajectories at Roundabouts in Germany,\u0026rdquo; in International Conference on Intelligent Transportation Systems (ITSC), 2020, pp. 1-6.\n","date":1629331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629331200,"objectID":"6be80eeca3528beaeaa6d54816c9a7e4","permalink":"https://tue-mps.github.io/post/2021-09-internship-vehicle-interaction/","publishdate":"2021-08-19T00:00:00Z","relpermalink":"/post/2021-09-internship-vehicle-interaction/","section":"post","summary":"Important note: this project is provisional, and the details may be subject to change.\nSummary: During this project, you will be able to model the interactions between vehicles to improve trajectory prediction of those vehicles.\n","tags":null,"title":"Towards Modeling Vehicle Interactions for the purpose of Path Prediction","type":"post"},{"authors":null,"categories":["Internship"],"content":"Important note: this project is provisional, and the details may be subject to change.\nSummary: During this project, you will apply a state-of-the-art imitation learning algorithm to the task of pedestrian path prediction.\nType: Internship\nStarting date: September 2021\nSupervisor: Ariyan Bighashdel\nGeneral description:\nPedestrian path prediction is an important problem in computer vision, with various applications such as autonomous vehicles and video surveillance. Despite significant progress over the past years, pedestrian path prediction has remained a complex problem, far from being solved.\nThe problem of pedestrian path prediction in the literature has been formulated in various ways, but conceptually all try to answer the following simple question:\n\u0026ldquo;Observing available information for a specific period of time, what will be the future positions of a target pedestrian in the next period of time?\u0026rdquo;\nThe proposed formulations may fundamentally differ in providing an answer to the above question. Path prediction approaches can be generally formulated as either a supervised learning (SL) problem or an imitation learning (IL) one. In the SL formulation, the idea is to train a (deep) model with a set of training input-output pairs. On the other hand, in the IL formulation, the goal is to train an agent to mimic the behavior of pedestrian from a set of (expert) pedestrian demonstrations.\nTo date, the SL formulation of the pedestrian path prediction task has received scant attention in the research literature and there is a surprisingly little amount of studies comparing two proposed formulations. Therefore, the goal is to compare both formulations in a well-controlled study.\nTask description: During this project, you will accomplish the following goals:\n Running an available pedestrian path prediction model with the encoder-decoder LSTM network. Running an available deep reinforcement learning algorithm for a general robotics task. Implementation of a pedestrian path prediction model using Generative Adversarial Imitation Learning [1]. Evaluation and comparison of the two prediction models in a well-controlled study.  Prerequisites:\n Experience with implementation of recurrent neural networks. General knowledge about reinforcement learning and/or high motivation to learn. Familiarity with simulation environments, (e.g. gym) and/or high motivation to learn  Interested? Send an email to a.bighashdel@tue.nl, containing:\n Brief motivation letter List of relevant courses and grades  References\n[1] J. Ho and S. Ermon, “Generative adversarial imitation learning,” in Advances in Neural Information Processing Systems, 2016, pp. 4565–4573.\n","date":1628812800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628812800,"objectID":"d1314855cfaa072417f1f108c9bd9a89","permalink":"https://tue-mps.github.io/post/2021-09-internship-trajectory-prediction/","publishdate":"2021-08-13T00:00:00Z","relpermalink":"/post/2021-09-internship-trajectory-prediction/","section":"post","summary":"Important note: this project is provisional, and the details may be subject to change.\nSummary: During this project, you will apply a state-of-the-art imitation learning algorithm to the task of pedestrian path prediction.\n","tags":null,"title":"Pedestrian Path Prediction via Imitation Learning with Inverse Reinforcement Learning","type":"post"},{"authors":null,"categories":["Internship"],"content":"Update: this project is not available anymore. It remains visible to show the type of student projects available at our group.\nSummary: During this project, you will improve an existing network for panoptic segmentation, to make it more accurate and efficient.\nType: Internship\nStarting date: September 2021\nSupervisor: Daan de Geus\nGeneral description:\nSelf-driving vehicles need situational awareness to be able to take appropriate actions. One way of gaining situational awareness is by applying scene understanding algorithms to cameras mounted on the vehicle. Panoptic segmentation is such a scene understanding task, which aims at recognizing all entities in a scene. Specifically, the goal is to predict, for each pixel, 1) a scene-class label (e.g., car, person, sky), 2) an instance id to distinguish between individual objects of countable classes (e.g., individual cars or persons).\nOver the past years, several deep neural networks have been developed for panoptic segmentation, with varying accuracies and efficiencies. Especially for self-driving vehicles, where real-time applicability is key, efficiency of neural networks is very important. For this purpose, the Fast Panoptic Segmentation Network (FPSNet) was introduced [1]. FPSNet achieves efficient panoptic segmentation by making use of a fast object detection backbone, and an attention mechanism that indicates the location of individual objects.\nHowever, recent work has outperformed FPSNet in terms of accuracy and efficiency, making use of various novel techniques. The goal of this internship is to leverage some of these techniques to improve the efficiency and accuracy of FPSNet.\nTask description: During this project, you will implement and evaluate several improvements to FPSNet. These improvements include:\n More supervision of objects attended by attention masks. More accurate attention masks, instead of using bell-shaped blobs. These could be generated by letting the network learn borderness of objects. More advanced panoptic head architecture. More efficient and accurate detection backbone. Further optimization of hyperparameters and learning strategy.  Prerequisites:\n Theoretical knowledge about deep neural networks for computer vision. Experience with implementing a deep neural network for computer vision.  Interested? Send an email to d.c.d.geus@tue.nl, containing:\n Brief motivation letter List of relevant courses and grades  References\n[1] D. de Geus, P. Meletis and G. Dubbelman, \u0026ldquo;Fast Panoptic Segmentation Network\u0026rdquo;, IEEE Robotics and Automation Letters, vol. 5, no. 2, pp. 1742-1749, 2020.\n","date":1625788800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625788800,"objectID":"f89fcc70b25f3b1ee5916838c789aa4e","permalink":"https://tue-mps.github.io/post/2021-09-internship-panoptic-segmentation/","publishdate":"2021-07-09T00:00:00Z","relpermalink":"/post/2021-09-internship-panoptic-segmentation/","section":"post","summary":"Update: this project is not available anymore. It remains visible to show the type of student projects available at our group.\nSummary: During this project, you will improve an existing network for panoptic segmentation, to make it more accurate and efficient.\n","tags":null,"title":"Accuracy and Efficiency Improvements for Fast Panoptic Segmentation","type":"post"},{"authors":["Test"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://tue-mps.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://tue-mps.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://tue-mps.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://tue-mps.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://tue-mps.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://tue-mps.github.io/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]